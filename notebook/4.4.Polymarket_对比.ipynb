{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6f3fd4e4",
      "metadata": {},
      "source": [
        "# 4.4 与 Polymarket 概率对比（仅目标公司）\n",
        "\n",
        "目标：基于 4.2/4.3 产出的 OOS 文本概率，与 Polymarket 的 Yes 隐含概率对照。\n",
        "\n",
        "最终对齐结果包含：\n",
        "- `ticker`\n",
        "- `quarter`\n",
        "- `y_true`\n",
        "- `p_text`\n",
        "- `p_poly`\n",
        "\n",
        "注意：必须是同一批 OOS 样本（`ticker + quarter` 对齐后交集）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ff55e6ca",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEXT_OOS_CSV: /Users/xinyuewang/Desktop/1.27/data/modeling/best_oos_probabilities_run_012.csv\n",
            "POLY_SOURCE: gamma\n",
            "EARNINGS_DB: /Users/xinyuewang/Desktop/1.27/data/earnings_calls.db\n",
            "TARGET_TICKERS: None\n"
          ]
        }
      ],
      "source": [
        "# ========== 配置 ==========\n",
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "import time\n",
        "import sqlite3\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import log_loss, brier_score_loss\n",
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "PROJECT_ROOT = Path(\"..\").resolve()\n",
        "MODEL_DIR = PROJECT_ROOT / \"data\" / \"modeling\"\n",
        "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 4.2/4.3 输出：优先使用 best_oos_probabilities_run_012.csv，不存在再用 oos_probabilities.csv\n",
        "TEXT_OOS_CANDIDATES = [\n",
        "    MODEL_DIR / \"best_oos_probabilities_run_012.csv\",\n",
        "    MODEL_DIR / \"oos_probabilities.csv\",\n",
        "    MODEL_DIR / \"oos_probabilities_logit_l2.csv\",\n",
        "    MODEL_DIR / \"oos_probabilities_logit_l1.csv\",\n",
        "]\n",
        "\n",
        "TEXT_OOS_CSV = next((p for p in TEXT_OOS_CANDIDATES if p.exists()), None)\n",
        "if TEXT_OOS_CSV is None:\n",
        "    raise FileNotFoundError(\"未找到 OOS 概率文件，请先运行 4.2/4.3\")\n",
        "\n",
        "# 目标公司：None 表示不过滤（推荐，避免漏掉 JPM）\n",
        "TARGET_TICKERS = None\n",
        "\n",
        "# p_poly 数据源：\"gamma\" / \"manual\" / \"url_map\"\n",
        "POLY_SOURCE = \"gamma\"\n",
        "\n",
        "# 手动模式文件（列要求：ticker, quarter, p_poly）\n",
        "POLY_DIRECT_CSV = MODEL_DIR / \"polymarket_probabilities_manual.csv\"\n",
        "\n",
        "# URL 映射模式文件（列要求：ticker, quarter, poly_api_url）\n",
        "POLY_MAP_CSV = MODEL_DIR / \"polymarket_market_map.csv\"\n",
        "\n",
        "# Gamma 自动模式配置\n",
        "EARNINGS_DB = PROJECT_ROOT / \"data\" / \"earnings_calls.db\"\n",
        "GAMMA_MARKETS_URL = \"https://gamma-api.polymarket.com/markets\"\n",
        "GAMMA_EVENTS_URL = \"https://gamma-api.polymarket.com/events\"\n",
        "GAMMA_HISTORY_URLS = [\n",
        "    \"https://clob.polymarket.com/prices-history\",\n",
        "    \"https://data-api.polymarket.com/prices-history\",\n",
        "]\n",
        "\n",
        "# 优先抓公告前 14 天内价格，失败再放宽\n",
        "LOOKBACK_DAYS = 14\n",
        "REQUEST_TIMEOUT = 20\n",
        "SLEEP_SECONDS = 0.2\n",
        "\n",
        "OUT_MERGED_CSV = MODEL_DIR / \"oos_text_vs_poly_target_tickers.csv\"\n",
        "OUT_METRICS_JSON = MODEL_DIR / \"oos_text_vs_poly_target_tickers_metrics.json\"\n",
        "OUT_GAP_CSV = MODEL_DIR / \"oos_text_vs_poly_mapping_gaps.csv\"\n",
        "OUT_GAMMA_MAP_CSV = MODEL_DIR / \"gamma_market_mapping.csv\"\n",
        "\n",
        "print(\"TEXT_OOS_CSV:\", TEXT_OOS_CSV)\n",
        "print(\"POLY_SOURCE:\", POLY_SOURCE)\n",
        "print(\"EARNINGS_DB:\", EARNINGS_DB)\n",
        "print(\"TARGET_TICKERS:\", TARGET_TICKERS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "70147354",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text rows: 307\n",
            "pairs: 307 missing announcement_time: 22\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 224\u001b[0m\n\u001b[1;32m    213\u001b[0m     rows\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m\"\u001b[39m: ticker, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquarter\u001b[39m\u001b[38;5;124m\"\u001b[39m: quarter, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp_poly\u001b[39m\u001b[38;5;124m\"\u001b[39m: p_poly})\n\u001b[1;32m    214\u001b[0m     map_rows\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m\"\u001b[39m: ticker,\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquarter\u001b[39m\u001b[38;5;124m\"\u001b[39m: quarter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp_poly\u001b[39m\u001b[38;5;124m\"\u001b[39m: p_poly,\n\u001b[1;32m    222\u001b[0m     })\n\u001b[0;32m--> 224\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(SLEEP_SECONDS)\n\u001b[1;32m    227\u001b[0m df_poly \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(rows)\n\u001b[1;32m    228\u001b[0m df_map \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(map_rows)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ========== Gamma 自动：market id -> price history -> announcement 前最后价格 ==========\n",
        "import re\n",
        "\n",
        "\n",
        "# 1) 读取 text 概率（ticker, quarter, y_true, p_text）\n",
        "def normalize_quarter(q):\n",
        "    if pd.isna(q):\n",
        "        return None\n",
        "    s = str(q).strip().upper().replace(\"_\", \"-\").replace(\" \", \"\")\n",
        "    if \"-Q\" in s:\n",
        "        return s\n",
        "    if len(s) >= 6 and s[:4].isdigit() and \"Q\" in s:\n",
        "        i = s.find(\"Q\")\n",
        "        return f\"{s[:4]}-Q{s[i+1:]}\"\n",
        "    return s\n",
        "\n",
        "\n",
        "def to_utc_dt(x):\n",
        "    if pd.isna(x):\n",
        "        return pd.NaT\n",
        "    s = str(x).strip().replace(\"Z\", \"+00:00\")\n",
        "    return pd.to_datetime(s, utc=True, errors=\"coerce\")\n",
        "\n",
        "\n",
        "def quarter_idx(q):\n",
        "    s = str(q).replace(\"-\", \"\")\n",
        "    m = re.match(r\"^(\\d{4})Q([1-4])$\", s)\n",
        "    if not m:\n",
        "        return np.nan\n",
        "    return int(m.group(1)) * 4 + int(m.group(2))\n",
        "\n",
        "\n",
        "df_text = pd.read_csv(TEXT_OOS_CSV)\n",
        "if \"actual\" in df_text.columns and \"y_true\" not in df_text.columns:\n",
        "    df_text = df_text.rename(columns={\"actual\": \"y_true\"})\n",
        "if \"fiscal_quarter\" in df_text.columns and \"quarter\" not in df_text.columns:\n",
        "    df_text = df_text.rename(columns={\"fiscal_quarter\": \"quarter\"})\n",
        "\n",
        "need_cols = [\"ticker\", \"quarter\", \"y_true\", \"p_text\"]\n",
        "missing = [c for c in need_cols if c not in df_text.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"OOS 文件缺少列: {missing}\")\n",
        "\n",
        "df_text = df_text[need_cols].copy()\n",
        "df_text[\"ticker\"] = df_text[\"ticker\"].astype(str).str.upper().str.strip()\n",
        "df_text[\"quarter\"] = df_text[\"quarter\"].apply(normalize_quarter)\n",
        "df_text[\"y_true\"] = pd.to_numeric(df_text[\"y_true\"], errors=\"coerce\")\n",
        "df_text[\"p_text\"] = pd.to_numeric(df_text[\"p_text\"], errors=\"coerce\")\n",
        "\n",
        "# 仅保留 OOS 期间\n",
        "df_text = df_text[df_text[\"quarter\"].map(quarter_idx) >= (2023 * 4 + 1)].copy()\n",
        "if TARGET_TICKERS is not None:\n",
        "    target = [t.upper().strip() for t in TARGET_TICKERS]\n",
        "    df_text = df_text[df_text[\"ticker\"].isin(target)].copy()\n",
        "\n",
        "df_text = df_text.dropna(subset=[\"ticker\", \"quarter\", \"y_true\", \"p_text\"]).drop_duplicates([\"ticker\", \"quarter\"])\n",
        "\n",
        "print(\"text rows:\", len(df_text))\n",
        "\n",
        "\n",
        "# 2) 找 announcement 时间（来自 earnings_calls.db 的 segments.timestamp 最早值）\n",
        "def get_announcement_map(pairs):\n",
        "    if not EARNINGS_DB.exists():\n",
        "        out = pairs.copy()\n",
        "        out[\"announcement_time\"] = pd.NaT\n",
        "        return out\n",
        "\n",
        "    conn = sqlite3.connect(EARNINGS_DB)\n",
        "    seg = pd.read_sql_query(\n",
        "        \"SELECT ticker, quarter, timestamp FROM segments WHERE timestamp IS NOT NULL AND timestamp <> ''\",\n",
        "        conn,\n",
        "    )\n",
        "    conn.close()\n",
        "\n",
        "    seg[\"ticker\"] = seg[\"ticker\"].astype(str).str.upper().str.strip()\n",
        "    seg[\"quarter\"] = seg[\"quarter\"].apply(normalize_quarter)\n",
        "    seg[\"timestamp\"] = seg[\"timestamp\"].apply(to_utc_dt)\n",
        "    seg = seg.dropna(subset=[\"ticker\", \"quarter\", \"timestamp\"])\n",
        "\n",
        "    ann = seg.groupby([\"ticker\", \"quarter\"], as_index=False)[\"timestamp\"].min()\n",
        "    ann = ann.rename(columns={\"timestamp\": \"announcement_time\"})\n",
        "\n",
        "    return pairs.merge(ann, on=[\"ticker\", \"quarter\"], how=\"left\")\n",
        "\n",
        "\n",
        "pairs = df_text[[\"ticker\", \"quarter\"]].drop_duplicates().copy()\n",
        "pairs = get_announcement_map(pairs)\n",
        "print(\"pairs:\", len(pairs), \"missing announcement_time:\", int(pairs[\"announcement_time\"].isna().sum()))\n",
        "\n",
        "\n",
        "# 3) Gamma: 找 market id\n",
        "def fetch_json(url, params=None):\n",
        "    try:\n",
        "        r = requests.get(url, params=params, timeout=REQUEST_TIMEOUT)\n",
        "        r.raise_for_status()\n",
        "        return r.json()\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def score_market(m, ticker, quarter):\n",
        "    q = str(m.get(\"question\", \"\") or m.get(\"title\", \"\") or \"\").lower()\n",
        "    s = str(m.get(\"slug\", \"\") or \"\").lower()\n",
        "    text = q + \" \" + s\n",
        "    sc = 0\n",
        "    if ticker.lower() in text:\n",
        "        sc += 3\n",
        "    if \"earnings\" in text:\n",
        "        sc += 2\n",
        "    if \"beat\" in text or \"miss\" in text:\n",
        "        sc += 2\n",
        "    if quarter.lower() in text or quarter.replace(\"-\", \"\").lower() in text:\n",
        "        sc += 1\n",
        "    return sc\n",
        "\n",
        "\n",
        "def find_gamma_market_id(ticker, quarter):\n",
        "    cands = []\n",
        "    for query in [f\"{ticker} earnings\", f\"{ticker} beat miss\", ticker]:\n",
        "        payload = fetch_json(GAMMA_MARKETS_URL, params={\"search\": query, \"limit\": 200})\n",
        "        if isinstance(payload, list):\n",
        "            cands.extend(payload)\n",
        "\n",
        "    if len(cands) == 0:\n",
        "        payload = fetch_json(GAMMA_EVENTS_URL, params={\"search\": f\"{ticker} earnings\", \"limit\": 200})\n",
        "        if isinstance(payload, list):\n",
        "            for e in payload:\n",
        "                for m in e.get(\"markets\", []) or []:\n",
        "                    cands.append(m)\n",
        "\n",
        "    if len(cands) == 0:\n",
        "        return None, None\n",
        "\n",
        "    scored = []\n",
        "    for m in cands:\n",
        "        mid = m.get(\"id\") or m.get(\"marketId\") or m.get(\"conditionId\")\n",
        "        if mid is None:\n",
        "            continue\n",
        "        scored.append((score_market(m, ticker, quarter), str(mid), str(m.get(\"question\") or m.get(\"title\") or \"\")))\n",
        "\n",
        "    if len(scored) == 0:\n",
        "        return None, None\n",
        "\n",
        "    scored.sort(key=lambda x: x[0], reverse=True)\n",
        "    return scored[0][1], scored[0][2]\n",
        "\n",
        "\n",
        "# 4) Gamma: 抓 price history，并取 announcement 前最后一个价格\n",
        "\n",
        "def parse_history(payload):\n",
        "    if payload is None:\n",
        "        return []\n",
        "    if isinstance(payload, dict):\n",
        "        arr = None\n",
        "        for k in [\"history\", \"prices\", \"data\"]:\n",
        "            if isinstance(payload.get(k), list):\n",
        "                arr = payload[k]\n",
        "                break\n",
        "        if arr is None:\n",
        "            arr = []\n",
        "    elif isinstance(payload, list):\n",
        "        arr = payload\n",
        "    else:\n",
        "        arr = []\n",
        "\n",
        "    out = []\n",
        "    for it in arr:\n",
        "        if not isinstance(it, dict):\n",
        "            continue\n",
        "        t = it.get(\"t\") or it.get(\"timestamp\") or it.get(\"time\")\n",
        "        p = it.get(\"p\") if it.get(\"p\") is not None else it.get(\"price\")\n",
        "        if t is None or p is None:\n",
        "            continue\n",
        "        try:\n",
        "            dt = pd.to_datetime(int(t), unit=\"s\", utc=True)\n",
        "            out.append((dt, float(p)))\n",
        "        except Exception:\n",
        "            pass\n",
        "    out.sort(key=lambda x: x[0])\n",
        "    return out\n",
        "\n",
        "\n",
        "def fetch_market_history(market_id):\n",
        "    for url in GAMMA_HISTORY_URLS:\n",
        "        payload = fetch_json(url, params={\"market\": market_id, \"interval\": \"max\", \"fidelity\": 1})\n",
        "        hist = parse_history(payload)\n",
        "        if len(hist) > 0:\n",
        "            return hist\n",
        "    return []\n",
        "\n",
        "\n",
        "rows = []\n",
        "map_rows = []\n",
        "for _, r in pairs.iterrows():\n",
        "    ticker = r[\"ticker\"]\n",
        "    quarter = r[\"quarter\"]\n",
        "    ann = r[\"announcement_time\"]\n",
        "\n",
        "    market_id, question = find_gamma_market_id(ticker, quarter)\n",
        "    p_poly = np.nan\n",
        "    price_ts = pd.NaT\n",
        "\n",
        "    if market_id is not None:\n",
        "        hist = fetch_market_history(market_id)\n",
        "        if len(hist) > 0:\n",
        "            if pd.notna(ann):\n",
        "                pre = [(t, p) for (t, p) in hist if t <= ann]\n",
        "            else:\n",
        "                pre = hist\n",
        "            if len(pre) > 0:\n",
        "                price_ts, p_poly = pre[-1]\n",
        "\n",
        "    rows.append({\"ticker\": ticker, \"quarter\": quarter, \"p_poly\": p_poly})\n",
        "    map_rows.append({\n",
        "        \"ticker\": ticker,\n",
        "        \"quarter\": quarter,\n",
        "        \"announcement_time\": ann,\n",
        "        \"market_id\": market_id,\n",
        "        \"market_question\": question,\n",
        "        \"price_ts\": price_ts,\n",
        "        \"p_poly\": p_poly,\n",
        "    })\n",
        "\n",
        "    time.sleep(SLEEP_SECONDS)\n",
        "\n",
        "\n",
        "df_poly = pd.DataFrame(rows)\n",
        "df_map = pd.DataFrame(map_rows)\n",
        "df_map.to_csv(OUT_GAMMA_MAP_CSV, index=False)\n",
        "print(\"gamma map saved:\", OUT_GAMMA_MAP_CSV)\n",
        "print(\"non-null p_poly:\", int(df_poly[\"p_poly\"].notna().sum()), \"/\", len(df_poly))\n",
        "\n",
        "\n",
        "# 5) 合并并导出最终对比表（你要的格式）\n",
        "df_cmp = df_text.merge(df_poly, on=[\"ticker\", \"quarter\"], how=\"inner\")\n",
        "df_cmp = df_cmp.dropna(subset=[\"y_true\", \"p_text\", \"p_poly\"]).copy()\n",
        "\n",
        "print(\"comparable rows:\", len(df_cmp))\n",
        "if len(df_cmp) == 0:\n",
        "    raise RuntimeError(\"Gamma 未匹配到可用 p_poly，请检查 OUT_GAMMA_MAP_CSV 的 market_id 与 price_ts\")\n",
        "\n",
        "out_cols = [\"ticker\", \"quarter\", \"y_true\", \"p_text\", \"p_poly\"]\n",
        "df_cmp[out_cols].to_csv(OUT_MERGED_CSV, index=False)\n",
        "\n",
        "y = df_cmp[\"y_true\"].astype(int).values\n",
        "p_text = df_cmp[\"p_text\"].astype(float).values\n",
        "p_poly = df_cmp[\"p_poly\"].astype(float).values\n",
        "metrics = {\n",
        "    \"n_samples\": int(len(df_cmp)),\n",
        "    \"logloss_text\": float(log_loss(y, p_text)),\n",
        "    \"logloss_poly\": float(log_loss(y, p_poly)),\n",
        "    \"brier_text\": float(brier_score_loss(y, p_text)),\n",
        "    \"brier_poly\": float(brier_score_loss(y, p_poly)),\n",
        "}\n",
        "with open(OUT_METRICS_JSON, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"saved:\", OUT_MERGED_CSV)\n",
        "print(\"saved:\", OUT_METRICS_JSON)\n",
        "print(\"saved:\", OUT_GAMMA_MAP_CSV)\n",
        "display(df_cmp[out_cols].head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "17128066",
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "BASE = \"https://gamma-api.polymarket.com\"\n",
        "\n",
        "def search_ebay_markets():\n",
        "    url = f\"{BASE}/markets\"\n",
        "    params = {\n",
        "        \"limit\": 1000,\n",
        "        \"closed\": \"true\"\n",
        "    }\n",
        "\n",
        "    r = requests.get(url, params=params, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    markets = r.json()\n",
        "\n",
        "    # 只筛选 EBAY earnings\n",
        "    ebay_markets = [\n",
        "        m for m in markets\n",
        "        if \"eBay\" in (m.get(\"question\") or \"\")\n",
        "        and \"beat\" in (m.get(\"question\") or \"\").lower()\n",
        "    ]\n",
        "\n",
        "    return ebay_markets\n",
        "\n",
        "\n",
        "data = search_ebay_markets()\n",
        "\n",
        "for m in data[:5]:\n",
        "    print(m[\"slug\"], m[\"endDate\"])\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
